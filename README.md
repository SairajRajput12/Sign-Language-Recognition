# ASL Sign Language to Text Converter

[![image](https://github.com/SairajRajput12/Sign-Language-Recognition/assets/125473711/742cd043-ba29-4566-aa7a-9e124cbf7473)]


## Introduction
This project aims to develop a real-time sign language to text converter using computer vision techniques, particularly OpenCV. The system detects hand gestures representing American Sign Language (ASL) signs and translates them into corresponding text characters.

## Features
- Real-time hand gesture detection and recognition.
- Translation of detected gestures into text characters.
- User-friendly graphical user interface (GUI).
- Support for a wide range of ASL signs.

## Technologies Used
- Python 3.10.0
- OpenCV library for computer vision tasks.
- TensorFlow 2.12 for machine learning-based hand classification.
- cvzone library for hand tracking and classification.
- Tkinter library for building the GUI.

## Setup Instructions
1. Clone this repository to your local machine.
   ```
   git clone https://github.com/SairajRajput12/Sign-Language-Recognition.git
   ```
2. Install the required Python and TensorFlow versions.
3. Run the run Python script to launch the application.
   ```
   python run.py
   ```
4. Follow the on-screen instructions to interact with the application.
   - Press 'k' to predict the ASL sign.
   - See the predicted sign and the resulting text output.

## Usage
- Position your hand in front of the webcam.
- Perform ASL signs within the camera frame.
- Press the 'k' key to predict the sign and see the corresponding text output.
- Repeat the process for different signs.

## Contributing
Contributions are welcome! If you want to contribute to this project, please follow these steps:
1. Fork the repository.
2. Create your feature branch (`git checkout -b feature/YourFeature`).
3. Commit your changes (`git commit -am 'Add some feature'`).
4. Push to the branch (`git push origin feature/YourFeature`).
5. Create a new Pull Request.
6. your contribution for gui will be helpful for us. 


---
